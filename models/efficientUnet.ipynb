{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"script for enet training\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ipython nbconvert --to=python enet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import functools\n",
    "import random\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.callbacks import LambdaCallback\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, \\\n",
    "    Add, Activation, BatchNormalization, Concatenate\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "from cb.tbi_cb import TensorBoardImage\n",
    "from cb.snapshot_cb_builder import SnapshotCallbackBuilder\n",
    "from cb.sgdr_lr_scheduler import SGDRScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU check\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir = \"/home/ubuntu/valdata/road_boundary_train/17_data/images\"\n",
    "# label_dir = \"/home/ubuntu/valdata/road_boundary_train/17_data/labels\"\n",
    "\n",
    "img_dir = \"/home/ubuntu/valdata/road_boundary_train/road_satellite/dataset/training/images\"\n",
    "label_dir = \"/home/ubuntu/valdata/road_boundary_train/road_satellite/dataset/training/masks\"\n",
    "\n",
    "MODEL_DIR = \"/home/ubuntu/valdata/road_boundary_train/road_satellite/enet\"\n",
    "\n",
    "alpha = K.variable(value=0.0)\n",
    "alpha._trainable = False\n",
    "\n",
    "OUTPUT_SHAPE = (512, 512, 1)\n",
    "INPUT_SHAPE = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "train_files = glob.glob(img_dir + \"/*.png\")\n",
    "train_label_files = []\n",
    "for x in train_files:\n",
    "    train_label_files.append(x.replace(\"images\", \"masks\"))\n",
    "\n",
    "    \n",
    "x_train_filenames, x_val_filenames, y_train_filenames, y_val_filenames = train_test_split(train_files,\n",
    "                                                                                          train_label_files,\n",
    "                                                                                          test_size=0.15,\n",
    "                                                                                          random_state=42)\n",
    "\n",
    "num_train_examples = len(x_train_filenames)\n",
    "num_val_examples = len(x_val_filenames)\n",
    "\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of validation examples: {}\".format(num_val_examples))\n",
    "\n",
    "img_shape = (512, 512, 3)\n",
    "batch_size = 4\n",
    "n_classes = 1\n",
    "epochs = 30\n",
    "BACKBONE = 'efficientnetb4'\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "\n",
    "def _process_pathnames(fname, label_path):\n",
    "    img_str = tf.io.read_file(fname)\n",
    "    img = tf.image.decode_png(img_str, channels=3)\n",
    "\n",
    "    label_img_str = tf.io.read_file(label_path)\n",
    "    label_img = tf.image.decode_png(label_img_str)\n",
    "\n",
    "    label_img = label_img[:, :, 0]\n",
    "    label_img = tf.expand_dims(label_img, axis=-1)\n",
    "    return img, label_img\n",
    "\n",
    "def flip_img(horizontal_flip, tr_img, label_img):\n",
    "    if horizontal_flip:\n",
    "        flip_prob = tf.random.uniform([], 0.0, 1.0)\n",
    "        tr_img, label_img = tf.cond(tf.math.less(flip_prob, 0.5),\n",
    "                                    lambda: (tf.image.flip_left_right(tr_img), tf.image.flip_left_right(label_img)),\n",
    "                                    lambda: (tr_img, label_img))\n",
    "    return tr_img, label_img\n",
    "\n",
    "\n",
    "def flip_img_vertically(vertical_flip, tr_img, label_img):\n",
    "    if vertical_flip:\n",
    "        flip_prob = tf.random.uniform([], 0.0, 1.0)\n",
    "        tr_img, label_img = tf.cond(tf.math.less(flip_prob, 0.5),\n",
    "                                    lambda: (tf.image.flip_up_down(tr_img), tf.image.flip_up_down(label_img)),\n",
    "                                    lambda: (tr_img, label_img))\n",
    "    return tr_img, label_img\n",
    "\n",
    "\n",
    "def _augment(img,\n",
    "             label_img,\n",
    "             resize=None,  # Resize the image to some size e.g. [256, 256]\n",
    "             scale=1,  # Scale image e.g. 1 / 255.\n",
    "             hue_delta=0,  # Adjust the hue of an RGB image by random factor\n",
    "             horizontal_flip=False,  # Random left right flip,\n",
    "             width_shift_range=0,  # Randomly translate the image horizontally\n",
    "             height_shift_range=0):  # Randomly translate the image vertically\n",
    "    if resize is not None:\n",
    "        # Resize both images\n",
    "        label_img = tf.image.resize(label_img, resize)\n",
    "        img = tf.image.resize(img, resize)\n",
    "\n",
    "    brightness_prob = tf.random.uniform([], 0.0, 1.0)\n",
    "    if tf.math.less(brightness_prob, 0.5):\n",
    "        img = tf.image.adjust_brightness(img, 0.2)\n",
    "        img = tf.image.random_contrast(img, lower=0.05, upper=0.5)\n",
    "\n",
    "    if hue_delta:\n",
    "        img = tf.image.random_hue(img, hue_delta)\n",
    "\n",
    "    img, label_img = flip_img(horizontal_flip, img, label_img)\n",
    "    img, label_img = flip_img_vertically(horizontal_flip, img, label_img)\n",
    "    \n",
    "    label_img = tf.cast(label_img, dtype=tf.float32) * scale\n",
    "    img = tf.cast(img, dtype=tf.float32) * scale\n",
    "    return img, label_img\n",
    "\n",
    "\n",
    "def _tb_augment(img, label_img):\n",
    "    label_img = tf.image.resize(label_img, [img_shape[0], img_shape[1]])\n",
    "    img = tf.image.resize(img, [img_shape[0], img_shape[1]])\n",
    "\n",
    "    label_img = tf.cast(label_img, dtype=tf.float32) * (1 / 255.)\n",
    "    img = tf.cast(img, dtype=tf.float32) * (1 / 255.)\n",
    "\n",
    "    return img, label_img\n",
    "\n",
    "\n",
    "def get_baseline_dataset(filenames,\n",
    "                         labels,\n",
    "                         preproc_fn=functools.partial(_augment),\n",
    "                         threads=6,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False):\n",
    "    num_x = len(filenames)\n",
    "    # Create a dataset from the filenames and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "    # Map our preprocessing function to every element in our dataset, taking\n",
    "    # advantage of multithreading\n",
    "    dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n",
    "    # print(dataset)\n",
    "    if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n",
    "        assert batch_size == 1, \"Batching images must be of the same size\"\n",
    "\n",
    "    dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(num_x)\n",
    "\n",
    "    # It's necessary to repeat our data for all epochs\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat()\n",
    "#     dataset = dataset.prefetch(2)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    # dataset = dataset.repeat().batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_tb_dataset(fnames,\n",
    "                   lnames,\n",
    "                   preproc_fn=functools.partial(_tb_augment),\n",
    "                   threads=6,\n",
    "                   batch_size=1,\n",
    "                   shuffle=True):\n",
    "    filenames, labels = zip(*random.sample(list(zip(fnames, lnames)), 300))\n",
    "    filenames = list(filenames)\n",
    "    labels = list(labels)\n",
    "    num_x = len(filenames)\n",
    "    # Create a dataset from the filenames and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "    dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n",
    "    # print(dataset)\n",
    "    if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n",
    "        assert batch_size == 1, \"Batching images must be of the same size\"\n",
    "\n",
    "    dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(num_x)\n",
    "\n",
    "    # It's necessary to repeat our data for all epochs\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat()\n",
    "#     dataset = dataset.prefetch(2)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # dataset = dataset.repeat().batch(batch_size)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "tr_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1 / 255.,\n",
    "    'hue_delta': 0.2,\n",
    "    'horizontal_flip': True,\n",
    "    'width_shift_range': 0.1,\n",
    "    'height_shift_range': 0.1\n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)\n",
    "\n",
    "val_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1 / 255.,\n",
    "}\n",
    "val_preprocessing_fn = functools.partial(_augment, **val_cfg)\n",
    "\n",
    "train_ds = get_baseline_dataset(x_train_filenames,\n",
    "                                y_train_filenames,\n",
    "                                preproc_fn=tr_preprocessing_fn,\n",
    "                                batch_size=batch_size)\n",
    "val_ds = get_baseline_dataset(x_val_filenames,\n",
    "                              y_val_filenames,\n",
    "                              preproc_fn=val_preprocessing_fn,\n",
    "                              batch_size=batch_size)\n",
    "tb_ds = get_tb_dataset(x_val_filenames, y_val_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS functions\n",
    "alpha = K.variable(value=0.1)\n",
    "alpha._trainable = False\n",
    "\n",
    "def update_alpha_value(epoch):\n",
    "    if epoch == 0:\n",
    "        K.set_value(alpha, 0.1)\n",
    "        print(f\"Setting alpha to = {K.get_value(alpha)}\")\n",
    "    if epoch > 5:\n",
    "        new_alpha = K.get_value(alpha) + 0.2\n",
    "        if new_alpha < 0.5:\n",
    "            K.set_value(alpha, new_alpha)\n",
    "        else:\n",
    "            K.set_value(alpha, 0.1)\n",
    "        print(f\"Setting alpha to = {K.get_value(alpha)}\")\n",
    "\n",
    "\n",
    "alpha_update_clb = LambdaCallback(on_epoch_begin=lambda epoch, log: update_alpha_value(epoch))\n",
    "\n",
    "\n",
    "def segmentation_boundary_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Using Binary Segmentation mask, generates boundary mask on fly and claculates boundary loss.\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_pred_bd = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_pred)\n",
    "    y_true_bd = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_true)\n",
    "    y_pred_bd = y_pred_bd - (1 - y_pred)\n",
    "    y_true_bd = y_true_bd - (1 - y_true)\n",
    "\n",
    "    y_pred_bd_ext = layers.MaxPooling2D((5, 5), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_pred)\n",
    "    y_true_bd_ext = layers.MaxPooling2D((5, 5), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_true)\n",
    "    y_pred_bd_ext = y_pred_bd_ext - (1 - y_pred)\n",
    "    y_true_bd_ext = y_true_bd_ext - (1 - y_true)\n",
    "\n",
    "    P = K.sum(y_pred_bd * y_true_bd_ext) / K.sum(y_pred_bd) + 1e-7\n",
    "    R = K.sum(y_true_bd * y_pred_bd_ext) / K.sum(y_true_bd) + 1e-7\n",
    "    F1_Score = 2 * P * R / (P + R + 1e-7)\n",
    "    # print(f'Precission: {P.eval()}, Recall: {R.eval()}, F1: {F1_Score.eval()}')\n",
    "    loss = K.mean(1 - F1_Score)\n",
    "    # print(f\"Loss:{loss.eval()}\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "def binary_focal_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    \"\"\"\n",
    "    alpha = 0.25\n",
    "    gamma = 2\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    epsilon = K.epsilon()\n",
    "    # clip to prevent NaN's and Inf's\n",
    "    pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "    pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "    return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "           - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "#     loss = (1 - alpha) * (binary_focal_loss(y_true, y_pred) + log_cosh_dce_loss(y_true,\n",
    "#                                                                                 y_pred)) + alpha * segmentation_boundary_loss(y_true, y_pred)\n",
    "    loss = (1 - alpha) * (losses.binary_crossentropy(y_true, y_pred) + log_cosh_dce_loss(y_true,\n",
    "                                                                                y_pred)) + alpha * segmentation_boundary_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def log_cosh_dce_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Implementation suggested in https://arxiv.org/pdf/2006.14822.pdf\n",
    "    \"\"\"\n",
    "    return tf.math.log(tf.math.cosh(dice_loss(y_true, y_pred)))\n",
    "\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = losses.binary_crossentropy(y_true, y_pred) + log_cosh_dce_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "\n",
    "steps_per_epoch = int(np.ceil(num_train_examples / float(batch_size)))\n",
    "validation_steps = int(np.ceil(num_val_examples / float(batch_size)))\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "logdir = f\"{MODEL_DIR}/logs/train_data/\"\n",
    "\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint(f'{MODEL_DIR}/enetRoadSegV1.h5',\n",
    "                                              save_best_only=True,\n",
    "                                              save_weights_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
    "tbi_callback = TensorBoardImage(logdir, data_set=tb_ds)\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=12)\n",
    "\n",
    "sgdr_lr = SGDRScheduler(min_lr=1e-5,\n",
    "                        max_lr=1e-2,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        swa_path=MODEL_DIR + \"/swa_weights/model_swa_{}.hdf5\",\n",
    "                        tb_log_dir=logdir,\n",
    "                        lr_decay=0.8,\n",
    "                        cycle_length=5,\n",
    "                        mult_factor=1.5)\n",
    "\n",
    "snapshot = SnapshotCallbackBuilder(sgdr_lr=sgdr_lr, nb_epochs=epochs, nb_snapshots=1, init_lr=1e-3)\n",
    "snapshot_callbacks = snapshot.get_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape = (img_shape[0], img_shape[1], 3))\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "#dice_loss = dice_coef_loss()\n",
    "#focal_loss = binary_focal_loss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "dice_loss_metrics = total_loss\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), sm.metrics.Precision(threshold=0.5),\n",
    "          sm.metrics.Recall(threshold=0.5), dice_loss_metrics]\n",
    "\n",
    "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=metrics)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "save_model_path = f\"{MODEL_DIR}/enetRoadSegF1.hdf5\"\n",
    "\n",
    "if os.path.exists(save_model_path):\n",
    "    model.load_weights(save_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "history = model.fit_generator(tf.compat.v1.data.make_one_shot_iterator(train_ds), validation_data=tf.compat.v1.data.make_one_shot_iterator(val_ds), validation_steps=validation_steps, epochs=epochs,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    callbacks=[mcp_save, tbCallBack, tbi_callback, earlystopping, alpha_update_clb] + snapshot_callbacks)\n",
    "\n",
    "final_model_path = f\"{MODEL_DIR}/enetRoadSegF1.hdf5\"\n",
    "model.save(final_model_path)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_sm_env)",
   "language": "python",
   "name": "conda_sm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
